{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5a59f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook exécuté depuis : /app/Model/ETL\n",
      "DATA_DIR  : /app/Model/OriginalData\n",
      "OUTPUT_DIR: /app/Model/ProcessedData\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    BASE_DIR = Path(__file__).resolve().parent\n",
    "except NameError:\n",
    "    BASE_DIR = Path.cwd()\n",
    "\n",
    "\n",
    "print(\"Notebook exécuté depuis :\", BASE_DIR)\n",
    "\n",
    "\n",
    "PROJECT_ROOT = BASE_DIR.parent           # /app/Model\n",
    "DATA_DIR     = PROJECT_ROOT / \"OriginalData\"\n",
    "OUTPUT_DIR   = PROJECT_ROOT / \"ProcessedData\"\n",
    "\n",
    "\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"DATA_DIR  :\", DATA_DIR)\n",
    "print(\"OUTPUT_DIR:\", OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1297f227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas version: 2.1.4\n",
      "numpy version: 1.26.2\n",
      "repertoire de travail: /app/Model/ETL\n",
      "fichiers disponibles: []\n"
     ]
    }
   ],
   "source": [
    "# importation des bibliotheques \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# configuration de l'affichage\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# verification de l'environnement\n",
    "print(f\"pandas version: {pd.__version__}\")\n",
    "print(f\"numpy version: {np.__version__}\")\n",
    "print(f\"repertoire de travail: {os.getcwd()}\")\n",
    "print(f\"fichiers disponibles: {[f for f in os.listdir('.') if f.endswith('.csv')]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87deb378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chargement des fichiers csv...\n",
      "\n",
      "covid dataset\n",
      "dimensions: (429435, 67)\n",
      "colonnes: ['iso_code', 'continent', 'location', 'date', 'total_cases', 'new_cases', 'new_cases_smoothed', 'total_deaths', 'new_deaths', 'new_deaths_smoothed', 'total_cases_per_million', 'new_cases_per_million', 'new_cases_smoothed_per_million', 'total_deaths_per_million', 'new_deaths_per_million', 'new_deaths_smoothed_per_million', 'reproduction_rate', 'icu_patients', 'icu_patients_per_million', 'hosp_patients', 'hosp_patients_per_million', 'weekly_icu_admissions', 'weekly_icu_admissions_per_million', 'weekly_hosp_admissions', 'weekly_hosp_admissions_per_million', 'total_tests', 'new_tests', 'total_tests_per_thousand', 'new_tests_per_thousand', 'new_tests_smoothed', 'new_tests_smoothed_per_thousand', 'positive_rate', 'tests_per_case', 'tests_units', 'total_vaccinations', 'people_vaccinated', 'people_fully_vaccinated', 'total_boosters', 'new_vaccinations', 'new_vaccinations_smoothed', 'total_vaccinations_per_hundred', 'people_vaccinated_per_hundred', 'people_fully_vaccinated_per_hundred', 'total_boosters_per_hundred', 'new_vaccinations_smoothed_per_million', 'new_people_vaccinated_smoothed', 'new_people_vaccinated_smoothed_per_hundred', 'stringency_index', 'population_density', 'median_age', 'aged_65_older', 'aged_70_older', 'gdp_per_capita', 'extreme_poverty', 'cardiovasc_death_rate', 'diabetes_prevalence', 'female_smokers', 'male_smokers', 'handwashing_facilities', 'hospital_beds_per_thousand', 'life_expectancy', 'human_development_index', 'population', 'excess_mortality_cumulative_absolute', 'excess_mortality_cumulative', 'excess_mortality', 'excess_mortality_cumulative_per_million']\n",
      "types de donnees:\n",
      "float64    61\n",
      "object      5\n",
      "int64       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      " mpox dataset \n",
      "dimensions: (123852, 15)\n",
      "colonnes: ['location', 'date', 'iso_code', 'total_cases', 'total_deaths', 'new_cases', 'new_deaths', 'new_cases_smoothed', 'new_deaths_smoothed', 'new_cases_per_million', 'total_cases_per_million', 'new_cases_smoothed_per_million', 'new_deaths_per_million', 'total_deaths_per_million', 'new_deaths_smoothed_per_million']\n",
      "types de donnees:\n",
      "float64    12\n",
      "object      3\n",
      "Name: count, dtype: int64\n",
      "\n",
      " taux de valeurs manquantes \n",
      "covid: 50.70%\n",
      "mpox: 0.06%\n"
     ]
    }
   ],
   "source": [
    "# chargement des donnees\n",
    "print(\"chargement des fichiers csv...\")\n",
    "covid_raw = pd.read_csv(DATA_DIR / 'covid_data.csv')\n",
    "mpox_raw = pd.read_csv(DATA_DIR / 'mpox_data.csv')\n",
    "\n",
    "# informations generales sur les datasets\n",
    "print(\"\\ncovid dataset\")\n",
    "print(f\"dimensions: {covid_raw.shape}\")\n",
    "print(f\"colonnes: {covid_raw.columns.tolist()}\")\n",
    "print(f\"types de donnees:\\n{covid_raw.dtypes.value_counts()}\")\n",
    "\n",
    "print(\"\\n mpox dataset \")\n",
    "print(f\"dimensions: {mpox_raw.shape}\")\n",
    "print(f\"colonnes: {mpox_raw.columns.tolist()}\")\n",
    "print(f\"types de donnees:\\n{mpox_raw.dtypes.value_counts()}\")\n",
    "\n",
    "# verification rapide des valeurs manquantes\n",
    "print(\"\\n taux de valeurs manquantes \")\n",
    "print(f\"covid: {covid_raw.isnull().sum().sum() / (covid_raw.shape[0] * covid_raw.shape[1]):.2%}\")\n",
    "print(f\"mpox: {mpox_raw.isnull().sum().sum() / (mpox_raw.shape[0] * mpox_raw.shape[1]):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "312cebf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " analyse des dates\n",
      "covid - type date: object\n",
      "covid - exemples dates: ['2020-01-05', '2020-01-06', '2020-01-07']\n",
      "covid - plage dates: 2020-01-01 a 2024-08-14\n",
      "\n",
      "mpox - type date: object\n",
      "mpox - exemples dates: ['2022-05-01', '2022-05-02', '2022-05-03']\n",
      "mpox - plage dates: 2022-05-01 a 2025-05-31\n",
      "\n",
      " analyse des locations\n",
      "covid - nombre locations uniques: 255\n",
      "mpox - nombre locations uniques: 144\n",
      "\n",
      "covid - agregations detectees (15): ['Africa', 'American Samoa', 'Asia', 'Central African Republic', 'Europe', 'European Union (27)', 'High-income countries', 'Low-income countries', 'Lower-middle-income countries', 'North America', 'Oceania', 'South Africa', 'South America', 'Upper-middle-income countries', 'World']\n",
      "\n",
      "mpox - agregations detectees (9): ['Africa', 'Asia', 'Central African Republic', 'Europe', 'North America', 'Oceania', 'South Africa', 'South America', 'World']\n",
      "\n",
      " colonnes communes (15)\n",
      "['date', 'iso_code', 'location', 'new_cases', 'new_cases_per_million', 'new_cases_smoothed', 'new_cases_smoothed_per_million', 'new_deaths', 'new_deaths_per_million', 'new_deaths_smoothed', 'new_deaths_smoothed_per_million', 'total_cases', 'total_cases_per_million', 'total_deaths', 'total_deaths_per_million']\n"
     ]
    }
   ],
   "source": [
    "# analyse detaillee de la structure des donnees\n",
    "print(\" analyse des dates\")\n",
    "print(f\"covid - type date: {covid_raw['date'].dtype}\")\n",
    "print(f\"covid - exemples dates: {covid_raw['date'].head(3).tolist()}\")\n",
    "print(f\"covid - plage dates: {covid_raw['date'].min()} a {covid_raw['date'].max()}\")\n",
    "\n",
    "print(f\"\\nmpox - type date: {mpox_raw['date'].dtype}\")\n",
    "print(f\"mpox - exemples dates: {mpox_raw['date'].head(3).tolist()}\")\n",
    "print(f\"mpox - plage dates: {mpox_raw['date'].min()} a {mpox_raw['date'].max()}\")\n",
    "\n",
    "# analyse des locations et agregations\n",
    "print(\"\\n analyse des locations\")\n",
    "covid_locations = covid_raw['location'].unique()\n",
    "mpox_locations = mpox_raw['location'].unique()\n",
    "\n",
    "print(f\"covid - nombre locations uniques: {len(covid_locations)}\")\n",
    "print(f\"mpox - nombre locations uniques: {len(mpox_locations)}\")\n",
    "\n",
    "# identification des agregations potentielles\n",
    "agregations_patterns = ['World', 'Europe', 'Asia', 'Africa', 'America', 'Oceania', 'income', 'Union']\n",
    "covid_agregations = [loc for loc in covid_locations if any(pattern in loc for pattern in agregations_patterns)]\n",
    "mpox_agregations = [loc for loc in mpox_locations if any(pattern in loc for pattern in agregations_patterns)]\n",
    "\n",
    "print(f\"\\ncovid - agregations detectees ({len(covid_agregations)}): {sorted(covid_agregations)}\")\n",
    "print(f\"\\nmpox - agregations detectees ({len(mpox_agregations)}): {sorted(mpox_agregations)}\")\n",
    "\n",
    "# verification des colonnes communes\n",
    "colonnes_communes = set(covid_raw.columns) & set(mpox_raw.columns)\n",
    "print(f\"\\n colonnes communes ({len(colonnes_communes)})\")\n",
    "print(sorted(colonnes_communes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "646fbc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversion des dates en datetime...\n",
      "conversion terminee\n",
      "covid - type date: datetime64[ns]\n",
      "mpox - type date: datetime64[ns]\n",
      "\n",
      " agregations reelles \n",
      "covid (12): ['Africa', 'Asia', 'Europe', 'European Union (27)', 'High-income countries', 'Low-income countries', 'Lower-middle-income countries', 'North America', 'Oceania', 'South America', 'Upper-middle-income countries', 'World']\n",
      "mpox (7): ['Africa', 'Asia', 'Europe', 'North America', 'Oceania', 'South America', 'World']\n",
      "\n",
      " verification des doublons (location, date) \n",
      "covid - doublons: 15540 lignes (7770 paires)\n",
      "mpox - doublons: 0 lignes (0 paires)\n"
     ]
    }
   ],
   "source": [
    "# conversion des dates en datetime\n",
    "print(\"conversion des dates en datetime...\")\n",
    "covid_raw['date'] = pd.to_datetime(covid_raw['date'])\n",
    "mpox_raw['date'] = pd.to_datetime(mpox_raw['date'])\n",
    "\n",
    "print(\"conversion terminee\")\n",
    "print(f\"covid - type date: {covid_raw['date'].dtype}\")\n",
    "print(f\"mpox - type date: {mpox_raw['date'].dtype}\")\n",
    "\n",
    "# affinement de la detection des agregations (exclure les pays)\n",
    "agregations_exactes = [\n",
    "    'World', 'Africa', 'Asia', 'Europe', 'North America', 'South America', 'Oceania',\n",
    "    'European Union', 'High-income countries', 'Low-income countries', \n",
    "    'Lower-middle-income countries', 'Upper-middle-income countries'\n",
    "]\n",
    "\n",
    "covid_agregations_reelles = []\n",
    "mpox_agregations_reelles = []\n",
    "\n",
    "for loc in covid_raw['location'].unique():\n",
    "    if any(ag in loc for ag in agregations_exactes):\n",
    "        # exclure les pays qui contiennent ces mots\n",
    "        if loc not in ['Central African Republic', 'South Africa', 'American Samoa']:\n",
    "            covid_agregations_reelles.append(loc)\n",
    "\n",
    "for loc in mpox_raw['location'].unique():\n",
    "    if any(ag in loc for ag in agregations_exactes):\n",
    "        # exclure les pays qui contiennent ces mots\n",
    "        if loc not in ['Central African Republic', 'South Africa']:\n",
    "            mpox_agregations_reelles.append(loc)\n",
    "\n",
    "print(f\"\\n agregations reelles \")\n",
    "print(f\"covid ({len(covid_agregations_reelles)}): {sorted(covid_agregations_reelles)}\")\n",
    "print(f\"mpox ({len(mpox_agregations_reelles)}): {sorted(mpox_agregations_reelles)}\")\n",
    "\n",
    "# verification de la presence de doublons avant traitement\n",
    "print(\"\\n verification des doublons (location, date) \")\n",
    "covid_doublons = covid_raw[covid_raw.duplicated(subset=['location', 'date'], keep=False)]\n",
    "mpox_doublons = mpox_raw[mpox_raw.duplicated(subset=['location', 'date'], keep=False)]\n",
    "\n",
    "print(f\"covid - doublons: {len(covid_doublons)} lignes ({len(covid_doublons)//2} paires)\")\n",
    "print(f\"mpox - doublons: {len(mpox_doublons)} lignes ({len(mpox_doublons)//2} paires)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a292806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " analyse des doublons covid \n",
      "exemple de doublons pour East Timor le 2021-02-12 00:00:00:\n",
      "          location       date  new_cases  total_cases  new_deaths  \\\n",
      "102540  East Timor 2021-02-12      0.000       80.000       0.000   \n",
      "380675  East Timor 2021-02-12        NaN          NaN         NaN   \n",
      "\n",
      "        total_deaths  \n",
      "102540         0.000  \n",
      "380675           NaN  \n",
      "\n",
      " pattern des doublons \n",
      "tous les doublons ont exactement 2 lignes: True\n",
      "pattern type - une ligne avec donnees, une avec peu/pas de donnees: 7660 / 7770\n",
      "\n",
      "exemples de patterns (nb valeurs non-nan min/max par paire):\n",
      "                       count  min  max\n",
      "location   date                       \n",
      "East Timor 2021-02-12      2   17   27\n",
      "           2021-02-13      2   17   27\n",
      "           2021-02-14      2   17   27\n",
      "           2021-02-15      2   17   27\n",
      "           2021-02-16      2   17   27\n"
     ]
    }
   ],
   "source": [
    "# analyse detaillee des doublons covid\n",
    "print(\" analyse des doublons covid \")\n",
    "if len(covid_doublons) > 0:\n",
    "    # exemple de doublons pour comprendre le pattern\n",
    "    exemple_location = covid_doublons['location'].iloc[0]\n",
    "    exemple_date = covid_doublons['date'].iloc[0]\n",
    "    \n",
    "    exemple_doublons = covid_raw[(covid_raw['location'] == exemple_location) & \n",
    "                                 (covid_raw['date'] == exemple_date)]\n",
    "    \n",
    "    print(f\"exemple de doublons pour {exemple_location} le {exemple_date}:\")\n",
    "    colonnes_interessantes = ['location', 'date', 'new_cases', 'total_cases', 'new_deaths', 'total_deaths']\n",
    "    print(exemple_doublons[colonnes_interessantes])\n",
    "    \n",
    "    # analyse du pattern des doublons\n",
    "    print(\"\\n pattern des doublons \")\n",
    "    # compter les valeurs non-nan pour chaque ligne dupliquee\n",
    "    covid_doublons_copy = covid_doublons.copy()\n",
    "    colonnes_numeriques = covid_raw.select_dtypes(include=[np.number]).columns\n",
    "    covid_doublons_copy['nb_valeurs_non_nan'] = covid_doublons_copy[colonnes_numeriques].notna().sum(axis=1)\n",
    "    \n",
    "    # grouper par location/date et voir la distribution\n",
    "    pattern_doublons = covid_doublons_copy.groupby(['location', 'date'])['nb_valeurs_non_nan'].agg(['count', 'min', 'max'])\n",
    "    print(f\"tous les doublons ont exactement 2 lignes: {(pattern_doublons['count'] == 2).all()}\")\n",
    "    print(f\"pattern type - une ligne avec donnees, une avec peu/pas de donnees: {(pattern_doublons['min'] < pattern_doublons['max']).sum()} / {len(pattern_doublons)}\")\n",
    "    \n",
    "    # verification que les doublons concernent bien des lignes complementaires\n",
    "    sample_pattern = pattern_doublons.head(5)\n",
    "    print(\"\\nexemples de patterns (nb valeurs non-nan min/max par paire):\")\n",
    "    print(sample_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c041e40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " traitement des doublons \n",
      "traitement des doublons sur ['location', 'date']...\n",
      "doublons trouves: 15540 lignes\n",
      "resultat: 429435 lignes -> 421665 lignes\n",
      "lignes supprimees: 7770\n",
      "traitement des doublons sur ['location', 'date']...\n",
      "aucun doublon trouve\n",
      "\n",
      " verification apres deduplication \n",
      "covid - doublons restants: 0\n",
      "mpox - doublons restants: 0\n"
     ]
    }
   ],
   "source": [
    "# fonction pour fusionner les lignes dupliquees\n",
    "def merge_duplicate_rows(df, subset=['location', 'date']):\n",
    "    \"\"\"\n",
    "    fusionne les lignes dupliquees en gardant les valeurs non-nan\n",
    "    \"\"\"\n",
    "    print(f\"traitement des doublons sur {subset}...\")\n",
    "    \n",
    "    # identifier les doublons\n",
    "    duplicated_mask = df.duplicated(subset=subset, keep=False)\n",
    "    df_no_dup = df[~duplicated_mask].copy()\n",
    "    df_dup = df[duplicated_mask].copy()\n",
    "    \n",
    "    if len(df_dup) == 0:\n",
    "        print(\"aucun doublon trouve\")\n",
    "        return df\n",
    "    \n",
    "    print(f\"doublons trouves: {len(df_dup)} lignes\")\n",
    "    \n",
    "    # pour chaque groupe de doublons, garder les valeurs non-nan\n",
    "    def merge_group(group):\n",
    "        # pour les colonnes numeriques, prendre la premiere valeur non-nan\n",
    "        numeric_cols = group.select_dtypes(include=[np.number]).columns\n",
    "        result = group.iloc[0].copy()\n",
    "        \n",
    "        for col in numeric_cols:\n",
    "            non_nan_values = group[col].dropna()\n",
    "            if len(non_nan_values) > 0:\n",
    "                result[col] = non_nan_values.iloc[0]\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    # appliquer la fusion\n",
    "    df_merged = df_dup.groupby(subset).apply(merge_group).reset_index(drop=True)\n",
    "    \n",
    "    # combiner avec les non-doublons\n",
    "    df_final = pd.concat([df_no_dup, df_merged], ignore_index=True)\n",
    "    \n",
    "    print(f\"resultat: {len(df)} lignes -> {len(df_final)} lignes\")\n",
    "    print(f\"lignes supprimees: {len(df) - len(df_final)}\")\n",
    "    \n",
    "    return df_final\n",
    "\n",
    "# application aux datasets\n",
    "print(\" traitement des doublons \")\n",
    "covid_dedup = merge_duplicate_rows(covid_raw, subset=['location', 'date'])\n",
    "mpox_dedup = merge_duplicate_rows(mpox_raw, subset=['location', 'date'])\n",
    "\n",
    "# verification\n",
    "print(\"\\n verification apres deduplication \")\n",
    "covid_doublons_apres = covid_dedup[covid_dedup.duplicated(subset=['location', 'date'], keep=False)]\n",
    "mpox_doublons_apres = mpox_dedup[mpox_dedup.duplicated(subset=['location', 'date'], keep=False)]\n",
    "print(f\"covid - doublons restants: {len(covid_doublons_apres)}\")\n",
    "print(f\"mpox - doublons restants: {len(mpox_doublons_apres)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ba4440b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " analyse des valeurs cumulatives decroissantes \n",
      "\n",
      "covid - verification total_cases:\n",
      "cas de decroissance: 20\n",
      "exemples:\n",
      "  location       date  valeur_actuelle  valeur_precedente  difference\n",
      "0   Belize 2022-04-10        57287.000          57289.000      -2.000\n",
      "1  Burundi 2023-07-16        54216.000          54321.000    -105.000\n",
      "2  Ecuador 2020-09-13       116451.000         118045.000   -1594.000\n",
      "\n",
      "covid - verification total_deaths:\n",
      "cas de decroissance: 15\n",
      "exemples:\n",
      "                          location       date  valeur_actuelle  \\\n",
      "0                        Australia 2023-07-23        22694.000   \n",
      "1  Bonaire Sint Eustatius and Saba 2021-10-17           19.000   \n",
      "2                           Canada 2022-06-19        41017.000   \n",
      "\n",
      "   valeur_precedente  difference  \n",
      "0          22770.000     -76.000  \n",
      "1             20.000      -1.000  \n",
      "2          41348.000    -331.000  \n",
      "\n",
      "mpox - verification total_cases:\n",
      "\n",
      "mpox - verification total_deaths:\n"
     ]
    }
   ],
   "source": [
    "# analyse des valeurs cumulatives decroissantes\n",
    "print(\" analyse des valeurs cumulatives decroissantes \")\n",
    "\n",
    "def check_cumulative_decrease(df, col, location_col='location'):\n",
    "    \"\"\"\n",
    "    verifie si une colonne cumulative decroit\n",
    "    \"\"\"\n",
    "    if col not in df.columns:\n",
    "        return None\n",
    "    \n",
    "    # trier par location et date\n",
    "    df_sorted = df.sort_values([location_col, 'date'])\n",
    "    \n",
    "    # calculer les differences pour chaque location\n",
    "    decreases = []\n",
    "    for location in df_sorted[location_col].unique():\n",
    "        loc_data = df_sorted[df_sorted[location_col] == location]\n",
    "        # ignorer les nan\n",
    "        values = loc_data[col].dropna()\n",
    "        if len(values) > 1:\n",
    "            diffs = values.diff()\n",
    "            negative_diffs = diffs[diffs < 0]\n",
    "            if len(negative_diffs) > 0:\n",
    "                for idx in negative_diffs.index:\n",
    "                    row = loc_data.loc[idx]\n",
    "                    prev_idx = values.index[values.index.get_loc(idx) - 1]\n",
    "                    prev_val = values.loc[prev_idx]\n",
    "                    decreases.append({\n",
    "                        'location': location,\n",
    "                        'date': row['date'],\n",
    "                        'valeur_actuelle': values.loc[idx],\n",
    "                        'valeur_precedente': prev_val,\n",
    "                        'difference': negative_diffs.loc[idx]\n",
    "                    })\n",
    "    \n",
    "    return pd.DataFrame(decreases)\n",
    "\n",
    "# verification pour covid\n",
    "print(\"\\ncovid - verification total_cases:\")\n",
    "covid_cases_decreases = check_cumulative_decrease(covid_dedup, 'total_cases')\n",
    "if covid_cases_decreases is not None and len(covid_cases_decreases) > 0:\n",
    "    print(f\"cas de decroissance: {len(covid_cases_decreases)}\")\n",
    "    print(\"exemples:\")\n",
    "    print(covid_cases_decreases.head(3))\n",
    "\n",
    "print(\"\\ncovid - verification total_deaths:\")\n",
    "covid_deaths_decreases = check_cumulative_decrease(covid_dedup, 'total_deaths')\n",
    "if covid_deaths_decreases is not None and len(covid_deaths_decreases) > 0:\n",
    "    print(f\"cas de decroissance: {len(covid_deaths_decreases)}\")\n",
    "    print(\"exemples:\")\n",
    "    print(covid_deaths_decreases.head(3))\n",
    "\n",
    "# verification pour mpox\n",
    "print(\"\\nmpox - verification total_cases:\")\n",
    "mpox_cases_decreases = check_cumulative_decrease(mpox_dedup, 'total_cases')\n",
    "if mpox_cases_decreases is not None and len(mpox_cases_decreases) > 0:\n",
    "    print(f\"cas de decroissance: {len(mpox_cases_decreases)}\")\n",
    "\n",
    "print(\"\\nmpox - verification total_deaths:\")\n",
    "mpox_deaths_decreases = check_cumulative_decrease(mpox_dedup, 'total_deaths')\n",
    "if mpox_deaths_decreases is not None and len(mpox_deaths_decreases) > 0:\n",
    "    print(f\"cas de decroissance: {len(mpox_deaths_decreases)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a4d0b66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " correction des valeurs cumulatives \n",
      "correction de total_cases...\n",
      "correction de total_deaths...\n",
      "correction de total_tests...\n",
      "correction de total_vaccinations...\n",
      "correction de people_vaccinated...\n",
      "correction de people_fully_vaccinated...\n",
      "correction de total_boosters...\n",
      "correction de total_cases...\n",
      "correction de total_deaths...\n",
      "\n",
      " verification apres correction \n",
      "covid - total_cases:\n",
      "cas de decroissance restants: 0\n",
      "\n",
      "covid - total_deaths:\n",
      "cas de decroissance restants: 0\n",
      "\n",
      " exemple de correction \n",
      "exemple pour Belize le 2022-04-10 00:00:00:\n",
      "valeur avant correction: 57287.0\n",
      "valeur apres correction: 57289.0\n"
     ]
    }
   ],
   "source": [
    "# correction des valeurs cumulatives decroissantes\n",
    "print(\" correction des valeurs cumulatives \")\n",
    "\n",
    "def fix_cumulative_values(df, cumulative_cols, location_col='location'):\n",
    "    \"\"\"\n",
    "    corrige les valeurs cumulatives avec cummax par location\n",
    "    \"\"\"\n",
    "    df_fixed = df.copy()\n",
    "    \n",
    "    for col in cumulative_cols:\n",
    "        if col in df_fixed.columns:\n",
    "            print(f\"correction de {col}...\")\n",
    "            # trier par location et date\n",
    "            df_fixed = df_fixed.sort_values([location_col, 'date'])\n",
    "            # appliquer cummax par location\n",
    "            df_fixed[col] = df_fixed.groupby(location_col)[col].transform(lambda x: x.cummax())\n",
    "    \n",
    "    return df_fixed\n",
    "\n",
    "# colonnes cumulatives a corriger\n",
    "cumulative_columns = ['total_cases', 'total_deaths', 'total_tests', 'total_vaccinations', \n",
    "                     'people_vaccinated', 'people_fully_vaccinated', 'total_boosters']\n",
    "\n",
    "# application des corrections\n",
    "covid_fixed = fix_cumulative_values(covid_dedup, cumulative_columns)\n",
    "mpox_fixed = fix_cumulative_values(mpox_dedup, ['total_cases', 'total_deaths'])\n",
    "\n",
    "# verification apres correction\n",
    "print(\"\\n verification apres correction \")\n",
    "print(\"covid - total_cases:\")\n",
    "covid_cases_decreases_after = check_cumulative_decrease(covid_fixed, 'total_cases')\n",
    "print(f\"cas de decroissance restants: {len(covid_cases_decreases_after) if covid_cases_decreases_after is not None else 0}\")\n",
    "\n",
    "print(\"\\ncovid - total_deaths:\")\n",
    "covid_deaths_decreases_after = check_cumulative_decrease(covid_fixed, 'total_deaths')\n",
    "print(f\"cas de decroissance restants: {len(covid_deaths_decreases_after) if covid_deaths_decreases_after is not None else 0}\")\n",
    "\n",
    "# verification que les valeurs ont bien ete corrigees\n",
    "print(\"\\n exemple de correction \")\n",
    "# prendre un exemple de correction\n",
    "if len(covid_cases_decreases) > 0:\n",
    "    exemple = covid_cases_decreases.iloc[0]\n",
    "    loc = exemple['location']\n",
    "    date = exemple['date']\n",
    "    \n",
    "    # valeurs avant/apres\n",
    "    avant = covid_dedup[(covid_dedup['location'] == loc) & (covid_dedup['date'] == date)]['total_cases'].iloc[0]\n",
    "    apres = covid_fixed[(covid_fixed['location'] == loc) & (covid_fixed['date'] == date)]['total_cases'].iloc[0]\n",
    "    \n",
    "    print(f\"exemple pour {loc} le {date}:\")\n",
    "    print(f\"valeur avant correction: {avant}\")\n",
    "    print(f\"valeur apres correction: {apres}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "001ea73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " analyse des lignes toutes nan \n",
      "covid - lignes avec toutes valeurs numeriques nan: 0\n",
      "\n",
      "mpox - lignes avec toutes valeurs numeriques nan: 1\n",
      "exemples:\n",
      "      location       date  total_cases  new_cases  total_deaths\n",
      "18272  Burundi 2024-07-19          NaN        NaN           NaN\n",
      "locations concernees: ['Burundi']\n",
      "\n",
      " suppression des lignes toutes nan \n",
      "covid: 421665 -> 421665 lignes (0 supprimees)\n",
      "mpox: 123852 -> 123851 lignes (1 supprimees)\n"
     ]
    }
   ],
   "source": [
    "# analyse des lignes avec toutes valeurs numeriques nan\n",
    "print(\" analyse des lignes toutes nan \")\n",
    "\n",
    "def find_all_nan_rows(df):\n",
    "    \"\"\"\n",
    "    trouve les lignes ou toutes les colonnes numeriques sont nan\n",
    "    \"\"\"\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    all_nan_mask = df[numeric_cols].isna().all(axis=1)\n",
    "    return df[all_nan_mask]\n",
    "\n",
    "# recherche dans covid\n",
    "covid_all_nan = find_all_nan_rows(covid_fixed)\n",
    "print(f\"covid - lignes avec toutes valeurs numeriques nan: {len(covid_all_nan)}\")\n",
    "if len(covid_all_nan) > 0:\n",
    "    print(\"exemples:\")\n",
    "    print(covid_all_nan[['location', 'date', 'total_cases', 'new_cases', 'total_deaths']].head())\n",
    "\n",
    "# recherche dans mpox\n",
    "mpox_all_nan = find_all_nan_rows(mpox_fixed)\n",
    "print(f\"\\nmpox - lignes avec toutes valeurs numeriques nan: {len(mpox_all_nan)}\")\n",
    "if len(mpox_all_nan) > 0:\n",
    "    print(\"exemples:\")\n",
    "    print(mpox_all_nan[['location', 'date', 'total_cases', 'new_cases', 'total_deaths']].head())\n",
    "    print(f\"locations concernees: {mpox_all_nan['location'].unique()}\")\n",
    "\n",
    "# suppression des lignes toutes nan\n",
    "print(\"\\n suppression des lignes toutes nan \")\n",
    "covid_cleaned = covid_fixed[~covid_fixed.index.isin(covid_all_nan.index)]\n",
    "mpox_cleaned = mpox_fixed[~mpox_fixed.index.isin(mpox_all_nan.index)]\n",
    "\n",
    "print(f\"covid: {len(covid_fixed)} -> {len(covid_cleaned)} lignes ({len(covid_all_nan)} supprimees)\")\n",
    "print(f\"mpox: {len(mpox_fixed)} -> {len(mpox_cleaned)} lignes ({len(mpox_all_nan)} supprimees)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2071c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " analyse des valeurs negatives \n",
      "covid - valeurs negatives:\n",
      "  reproduction_rate: 178 valeurs, min=-0.070, max=-0.010, 14 locations\n",
      "\n",
      "mpox - valeurs negatives:\n",
      "\n",
      " exemples de reproduction_rate negatif \n",
      "      location       date  reproduction_rate  new_cases  total_cases\n",
      "11062   Angola 2022-10-19             -0.010      0.000   103299.000\n",
      "11069   Angola 2022-10-26             -0.010      0.000   103414.000\n",
      "17823  Armenia 2022-12-19             -0.070      0.000   445525.000\n",
      "17836  Armenia 2023-01-01             -0.010     37.000   445620.000\n",
      "17837  Armenia 2023-01-02             -0.070      0.000   445620.000\n"
     ]
    }
   ],
   "source": [
    "# analyse des valeurs negatives\n",
    "print(\" analyse des valeurs negatives \")\n",
    "\n",
    "# fonction pour analyser les valeurs negatives\n",
    "def analyze_negative_values(df, columns_to_check):\n",
    "    \"\"\"\n",
    "    analyse les valeurs negatives dans les colonnes specifiees\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    for col in columns_to_check:\n",
    "        if col in df.columns:\n",
    "            negative_mask = df[col] < 0\n",
    "            negative_values = df[negative_mask]\n",
    "            if len(negative_values) > 0:\n",
    "                results[col] = {\n",
    "                    'count': len(negative_values),\n",
    "                    'min': df[col].min(),\n",
    "                    'max': negative_values[col].max(),\n",
    "                    'locations': len(negative_values['location'].unique())\n",
    "                }\n",
    "    return results\n",
    "\n",
    "# colonnes a verifier pour valeurs negatives\n",
    "cols_to_check = ['reproduction_rate', 'new_cases', 'new_deaths', 'total_cases', 'total_deaths']\n",
    "\n",
    "# analyse covid\n",
    "print(\"covid - valeurs negatives:\")\n",
    "covid_negatives = analyze_negative_values(covid_cleaned, cols_to_check)\n",
    "for col, stats in covid_negatives.items():\n",
    "    print(f\"  {col}: {stats['count']} valeurs, min={stats['min']:.3f}, max={stats['max']:.3f}, {stats['locations']} locations\")\n",
    "\n",
    "# analyse mpox\n",
    "print(\"\\nmpox - valeurs negatives:\")\n",
    "mpox_negatives = analyze_negative_values(mpox_cleaned, cols_to_check)\n",
    "for col, stats in mpox_negatives.items():\n",
    "    print(f\"  {col}: {stats['count']} valeurs, min={stats['min']:.3f}, max={stats['max']:.3f}, {stats['locations']} locations\")\n",
    "\n",
    "# exemples de reproduction_rate negatif\n",
    "if 'reproduction_rate' in covid_negatives:\n",
    "    print(\"\\n exemples de reproduction_rate negatif \")\n",
    "    negative_repro = covid_cleaned[covid_cleaned['reproduction_rate'] < 0]\n",
    "    print(negative_repro[['location', 'date', 'reproduction_rate', 'new_cases', 'total_cases']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73b3bd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " correction des valeurs negatives \n",
      "correction du reproduction_rate negatif...\n",
      "reproduction_rate: 178 valeurs negatives remplacees par 0\n",
      "valeurs negatives restantes: 0\n",
      "\n",
      " analyse du mortality_rate \n",
      "le mortality_rate n'existe pas dans les donnees, il faudra le calculer\n",
      "formule: mortality_rate = (total_deaths / total_cases) * 100\n",
      "\n",
      "covid - 'mortality_rate' present: False\n",
      "mpox - 'mortality_rate' present: False\n",
      "\n",
      " test du calcul mortality_rate \n",
      "valeurs > 100%: 0\n",
      "valeurs infinies: 0\n",
      "valeurs nan (0/0): 56\n"
     ]
    }
   ],
   "source": [
    "# correction des valeurs negatives\n",
    "print(\" correction des valeurs negatives \")\n",
    "\n",
    "# correction du reproduction_rate negatif\n",
    "if 'reproduction_rate' in covid_cleaned.columns:\n",
    "    print(\"correction du reproduction_rate negatif...\")\n",
    "    mask_negative = covid_cleaned['reproduction_rate'] < 0\n",
    "    nb_corrections = mask_negative.sum()\n",
    "    covid_cleaned.loc[mask_negative, 'reproduction_rate'] = 0\n",
    "    print(f\"reproduction_rate: {nb_corrections} valeurs negatives remplacees par 0\")\n",
    "    \n",
    "    # verification\n",
    "    nb_negative_after = (covid_cleaned['reproduction_rate'] < 0).sum()\n",
    "    print(f\"valeurs negatives restantes: {nb_negative_after}\")\n",
    "\n",
    "# analyse du mortality_rate\n",
    "print(\"\\n analyse du mortality_rate \")\n",
    "print(\"le mortality_rate n'existe pas dans les donnees, il faudra le calculer\")\n",
    "print(\"formule: mortality_rate = (total_deaths / total_cases) * 100\")\n",
    "\n",
    "# verification de la presence de mortality_rate\n",
    "print(f\"\\ncovid - 'mortality_rate' present: {'mortality_rate' in covid_cleaned.columns}\")\n",
    "print(f\"mpox - 'mortality_rate' present: {'mortality_rate' in mpox_cleaned.columns}\")\n",
    "\n",
    "# calcul preliminaire pour voir les problemes potentiels\n",
    "print(\"\\n test du calcul mortality_rate \")\n",
    "# test sur un echantillon\n",
    "covid_sample = covid_cleaned[covid_cleaned['total_deaths'].notna() & covid_cleaned['total_cases'].notna()].head(1000)\n",
    "if len(covid_sample) > 0:\n",
    "    test_mortality = (covid_sample['total_deaths'] / covid_sample['total_cases']) * 100\n",
    "    print(f\"valeurs > 100%: {(test_mortality > 100).sum()}\")\n",
    "    print(f\"valeurs infinies: {np.isinf(test_mortality).sum()}\")\n",
    "    print(f\"valeurs nan (0/0): {test_mortality.isna().sum()}\")\n",
    "    \n",
    "    if (test_mortality > 100).any():\n",
    "        print(\"\\nexemples de mortality_rate > 100%:\")\n",
    "        problematic = covid_sample[test_mortality > 100][['location', 'date', 'total_deaths', 'total_cases']]\n",
    "        print(problematic.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "52fdcb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " separation pays vs agregations \n",
      "covid - pays: 401502 lignes, 243 locations\n",
      "covid - agregations: 20163 lignes, 12 locations\n",
      "\n",
      "mpox - pays: 116057 lignes, 137 locations\n",
      "mpox - agregations: 7794 lignes, 7 locations\n",
      "\n",
      " verification des separations \n",
      "covid - locations agregations: ['Africa', 'Asia', 'Europe', 'European Union (27)', 'High-income countries', 'Low-income countries', 'Lower-middle-income countries', 'North America', 'Oceania', 'South America', 'Upper-middle-income countries', 'World']\n",
      "\n",
      "mpox - locations agregations: ['Africa', 'Asia', 'Europe', 'North America', 'Oceania', 'South America', 'World']\n",
      "South Africa - dans covid pays: True, dans mpox pays: True\n",
      "Central African Republic - dans covid pays: True, dans mpox pays: True\n",
      "American Samoa - dans covid pays: True, dans mpox pays: False\n"
     ]
    }
   ],
   "source": [
    "# separation pays vs agregations\n",
    "print(\" separation pays vs agregations \")\n",
    "\n",
    "# listes des agregations identifiees precedemment\n",
    "covid_agregations_list = ['Africa', 'Asia', 'Europe', 'European Union (27)', \n",
    "                         'High-income countries', 'Low-income countries', \n",
    "                         'Lower-middle-income countries', 'North America', \n",
    "                         'Oceania', 'South America', 'Upper-middle-income countries', 'World']\n",
    "\n",
    "mpox_agregations_list = ['Africa', 'Asia', 'Europe', 'North America', \n",
    "                        'Oceania', 'South America', 'World']\n",
    "\n",
    "# separation covid\n",
    "covid_countries = covid_cleaned[~covid_cleaned['location'].isin(covid_agregations_list)]\n",
    "covid_aggregations = covid_cleaned[covid_cleaned['location'].isin(covid_agregations_list)]\n",
    "\n",
    "print(f\"covid - pays: {len(covid_countries)} lignes, {covid_countries['location'].nunique()} locations\")\n",
    "print(f\"covid - agregations: {len(covid_aggregations)} lignes, {covid_aggregations['location'].nunique()} locations\")\n",
    "\n",
    "# separation mpox\n",
    "mpox_countries = mpox_cleaned[~mpox_cleaned['location'].isin(mpox_agregations_list)]\n",
    "mpox_aggregations = mpox_cleaned[mpox_cleaned['location'].isin(mpox_agregations_list)]\n",
    "\n",
    "print(f\"\\nmpox - pays: {len(mpox_countries)} lignes, {mpox_countries['location'].nunique()} locations\")\n",
    "print(f\"mpox - agregations: {len(mpox_aggregations)} lignes, {mpox_aggregations['location'].nunique()} locations\")\n",
    "\n",
    "# verification des locations\n",
    "print(\"\\n verification des separations \")\n",
    "print(f\"covid - locations agregations: {sorted(covid_aggregations['location'].unique())}\")\n",
    "print(f\"\\nmpox - locations agregations: {sorted(mpox_aggregations['location'].unique())}\")\n",
    "\n",
    "# verification qu'aucun pays n'a ete mal classe\n",
    "pays_suspects = ['South Africa', 'Central African Republic', 'American Samoa']\n",
    "for pays in pays_suspects:\n",
    "    if pays in covid_agregations_list or pays in mpox_agregations_list:\n",
    "        print(f\"attention: {pays} classe comme agregation!\")\n",
    "    else:\n",
    "        in_covid = pays in covid_countries['location'].values\n",
    "        in_mpox = pays in mpox_countries['location'].values\n",
    "        print(f\"{pays} - dans covid pays: {in_covid}, dans mpox pays: {in_mpox}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e185918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " enrichissement de mpox avec donnees covid \n",
      "extraction des donnees statiques de covid...\n",
      "donnees statiques extraites pour 243 pays\n",
      "\n",
      "enrichissement de mpox...\n",
      "nombre de valeurs ajoutees: 1502068\n",
      "\n",
      " verification de l'enrichissement \n",
      "population: 0 -> 116057 valeurs non-nan\n",
      "population_density: 0 -> 113870 valeurs non-nan\n",
      "\n",
      "exemple pour Albania:\n",
      "population: 2842318.0\n",
      "population_density: 104.87\n"
     ]
    }
   ],
   "source": [
    "# enrichissement de mpox avec donnees statiques de covid\n",
    "print(\" enrichissement de mpox avec donnees covid \")\n",
    "\n",
    "# colonnes statiques a recuperer de covid (ne changent pas avec le temps)\n",
    "colonnes_statiques = ['population', 'population_density', 'median_age', 'aged_65_older', \n",
    "                     'aged_70_older', 'gdp_per_capita', 'extreme_poverty', \n",
    "                     'cardiovasc_death_rate', 'diabetes_prevalence', 'female_smokers', \n",
    "                     'male_smokers', 'handwashing_facilities', 'hospital_beds_per_thousand', \n",
    "                     'life_expectancy', 'human_development_index']\n",
    "\n",
    "# pour chaque pays, recuperer les valeurs statiques les plus recentes de covid\n",
    "print(\"extraction des donnees statiques de covid...\")\n",
    "covid_static_data = {}\n",
    "\n",
    "for location in covid_countries['location'].unique():\n",
    "    loc_data = covid_countries[covid_countries['location'] == location]\n",
    "    # prendre la ligne la plus recente\n",
    "    latest_data = loc_data.sort_values('date', ascending=False).iloc[0]\n",
    "    \n",
    "    static_values = {}\n",
    "    for col in colonnes_statiques:\n",
    "        if col in latest_data.index:\n",
    "            value = latest_data[col]\n",
    "            # garder seulement si non nan\n",
    "            if pd.notna(value):\n",
    "                static_values[col] = value\n",
    "    \n",
    "    if static_values:\n",
    "        covid_static_data[location] = static_values\n",
    "\n",
    "print(f\"donnees statiques extraites pour {len(covid_static_data)} pays\")\n",
    "\n",
    "# enrichir mpox_countries\n",
    "print(\"\\nenrichissement de mpox...\")\n",
    "mpox_enriched = mpox_countries.copy()\n",
    "\n",
    "# ajouter les colonnes si elles n'existent pas\n",
    "for col in colonnes_statiques:\n",
    "    if col not in mpox_enriched.columns:\n",
    "        mpox_enriched[col] = np.nan\n",
    "\n",
    "# remplir avec les donnees statiques\n",
    "nb_enrichissements = 0\n",
    "for idx, row in mpox_enriched.iterrows():\n",
    "    location = row['location']\n",
    "    if location in covid_static_data:\n",
    "        for col, value in covid_static_data[location].items():\n",
    "            if pd.isna(mpox_enriched.at[idx, col]):\n",
    "                mpox_enriched.at[idx, col] = value\n",
    "                nb_enrichissements += 1\n",
    "\n",
    "print(f\"nombre de valeurs ajoutees: {nb_enrichissements}\")\n",
    "\n",
    "# verification de l'enrichissement\n",
    "print(\"\\n verification de l'enrichissement \")\n",
    "for col in ['population', 'population_density']:\n",
    "    avant = mpox_countries[col].notna().sum() if col in mpox_countries.columns else 0\n",
    "    apres = mpox_enriched[col].notna().sum()\n",
    "    print(f\"{col}: {avant} -> {apres} valeurs non-nan\")\n",
    "\n",
    "# exemple d'enrichissement\n",
    "exemple_location = mpox_enriched['location'].iloc[0]\n",
    "print(f\"\\nexemple pour {exemple_location}:\")\n",
    "print(f\"population: {mpox_enriched[mpox_enriched['location'] == exemple_location]['population'].iloc[0]}\")\n",
    "print(f\"population_density: {mpox_enriched[mpox_enriched['location'] == exemple_location]['population_density'].iloc[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "663fd232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " calcul du mortality_rate \n",
      "calcul pour covid...\n",
      "valeurs > 100% detectees: 196\n",
      "valeurs > 100% detectees: 49\n",
      "\n",
      "calcul pour mpox...\n",
      "\n",
      " verification mortality_rate \n",
      "\n",
      "covid_countries:\n",
      "  min: 0.000\n",
      "  max: 100.000\n",
      "  moyenne: 1.776\n",
      "  valeurs non-nan: 362629\n",
      "\n",
      "mpox_enriched:\n",
      "  min: 0.000\n",
      "  max: 100.000\n",
      "  moyenne: 1.227\n",
      "  valeurs non-nan: 115281\n"
     ]
    }
   ],
   "source": [
    "# calcul du mortality_rate\n",
    "print(\" calcul du mortality_rate \")\n",
    "\n",
    "def calculate_mortality_rate(df):\n",
    "    \"\"\"\n",
    "    calcule le mortality_rate de facon robuste\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # calcul de base\n",
    "    df_copy['mortality_rate'] = (df_copy['total_deaths'] / df_copy['total_cases']) * 100\n",
    "    \n",
    "    # gestion des cas speciaux\n",
    "    # cas ou total_cases = 0 (division par zero -> inf)\n",
    "    mask_zero_cases = df_copy['total_cases'] == 0\n",
    "    df_copy.loc[mask_zero_cases, 'mortality_rate'] = np.nan\n",
    "    \n",
    "    # cas ou mortality_rate > 100% (erreur de donnees)\n",
    "    mask_over_100 = df_copy['mortality_rate'] > 100\n",
    "    if mask_over_100.sum() > 0:\n",
    "        print(f\"valeurs > 100% detectees: {mask_over_100.sum()}\")\n",
    "        df_copy.loc[mask_over_100, 'mortality_rate'] = 100.0\n",
    "    \n",
    "    # remplacer les inf par nan\n",
    "    df_copy['mortality_rate'] = df_copy['mortality_rate'].replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "# application aux deux datasets\n",
    "print(\"calcul pour covid...\")\n",
    "covid_countries = calculate_mortality_rate(covid_countries)\n",
    "covid_aggregations = calculate_mortality_rate(covid_aggregations)\n",
    "\n",
    "print(\"\\ncalcul pour mpox...\")\n",
    "mpox_enriched = calculate_mortality_rate(mpox_enriched)\n",
    "mpox_aggregations = calculate_mortality_rate(mpox_aggregations)\n",
    "\n",
    "# verification\n",
    "print(\"\\n verification mortality_rate \")\n",
    "for name, df in [('covid_countries', covid_countries), ('mpox_enriched', mpox_enriched)]:\n",
    "    if 'mortality_rate' in df.columns:\n",
    "        stats = df['mortality_rate'].describe()\n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"  min: {stats['min']:.3f}\")\n",
    "        print(f\"  max: {stats['max']:.3f}\")\n",
    "        print(f\"  moyenne: {stats['mean']:.3f}\")\n",
    "        print(f\"  valeurs non-nan: {df['mortality_rate'].notna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "57e53cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " selection des colonnes finales \n",
      "nombre total de colonnes a garder: 20\n",
      "\n",
      " verification disponibilite colonnes \n",
      "\n",
      "covid_countries:\n",
      "  colonnes presentes: 20/20\n",
      "  population_density: 89.0% de valeurs non-nan\n",
      "  stringency_index: 48.9% de valeurs non-nan\n",
      "\n",
      "mpox_enriched:\n",
      "  colonnes presentes: 17/20\n",
      "  colonnes manquantes: ['continent', 'reproduction_rate', 'stringency_index']\n",
      "  population_density: 98.1% de valeurs non-nan\n",
      "\n",
      " datasets finaux \n",
      "covid_countries: (401502, 20)\n",
      "mpox_enriched: (116057, 17)\n"
     ]
    }
   ],
   "source": [
    "# selection des colonnes finales\n",
    "print(\" selection des colonnes finales \")\n",
    "\n",
    "# definition des colonnes essentielles\n",
    "colonnes_identifiants = ['iso_code', 'continent', 'location', 'date']\n",
    "colonnes_transmission = ['new_cases', 'total_cases', 'new_cases_smoothed', \n",
    "                        'new_cases_per_million', 'new_cases_smoothed_per_million', \n",
    "                        'reproduction_rate']\n",
    "colonnes_mortalite = ['new_deaths', 'total_deaths', 'new_deaths_smoothed', \n",
    "                     'new_deaths_per_million', 'new_deaths_smoothed_per_million', \n",
    "                     'total_deaths_per_million', 'mortality_rate']\n",
    "colonnes_population = ['population', 'population_density']\n",
    "colonnes_politique = ['stringency_index']\n",
    "\n",
    "# toutes les colonnes a garder\n",
    "colonnes_finales = (colonnes_identifiants + colonnes_transmission + \n",
    "                   colonnes_mortalite + colonnes_population + colonnes_politique)\n",
    "\n",
    "print(f\"nombre total de colonnes a garder: {len(colonnes_finales)}\")\n",
    "\n",
    "# verification de la disponibilite des colonnes\n",
    "print(\"\\n verification disponibilite colonnes \")\n",
    "for dataset_name, dataset in [('covid_countries', covid_countries), \n",
    "                              ('mpox_enriched', mpox_enriched)]:\n",
    "    print(f\"\\n{dataset_name}:\")\n",
    "    colonnes_manquantes = [col for col in colonnes_finales if col not in dataset.columns]\n",
    "    colonnes_presentes = [col for col in colonnes_finales if col in dataset.columns]\n",
    "    \n",
    "    print(f\"  colonnes presentes: {len(colonnes_presentes)}/{len(colonnes_finales)}\")\n",
    "    if colonnes_manquantes:\n",
    "        print(f\"  colonnes manquantes: {colonnes_manquantes}\")\n",
    "    \n",
    "    # taux de remplissage pour les colonnes a tester\n",
    "    for col in ['population_density', 'stringency_index']:\n",
    "        if col in dataset.columns:\n",
    "            taux = dataset[col].notna().sum() / len(dataset) * 100\n",
    "            print(f\"  {col}: {taux:.1f}% de valeurs non-nan\")\n",
    "\n",
    "# selection des colonnes disponibles\n",
    "covid_countries_final = covid_countries[[col for col in colonnes_finales if col in covid_countries.columns]]\n",
    "mpox_enriched_final = mpox_enriched[[col for col in colonnes_finales if col in mpox_enriched.columns]]\n",
    "\n",
    "print(f\"\\n datasets finaux \")\n",
    "print(f\"covid_countries: {covid_countries_final.shape}\")\n",
    "print(f\"mpox_enriched: {mpox_enriched_final.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b46b55b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " enrichissement des colonnes manquantes dans mpox \n",
      "ajout de la colonne continent...\n",
      "continent ajoute pour 116057 lignes\n",
      "\n",
      "ajout de stringency_index...\n",
      "stringency_index ajoute pour 18035 lignes\n",
      "\n",
      "reproduction_rate: specifique a chaque maladie, ne peut pas etre transfere\n",
      "\n",
      " validation finale \n",
      "covid_countries_final: (401502, 20)\n",
      "colonnes: ['iso_code', 'continent', 'location', 'date', 'new_cases', 'total_cases', 'new_cases_smoothed', 'new_cases_per_million', 'new_cases_smoothed_per_million', 'reproduction_rate', 'new_deaths', 'total_deaths', 'new_deaths_smoothed', 'new_deaths_per_million', 'new_deaths_smoothed_per_million', 'total_deaths_per_million', 'mortality_rate', 'population', 'population_density', 'stringency_index']\n",
      "\n",
      "mpox_enriched_final: (116057, 19)\n",
      "colonnes: ['iso_code', 'continent', 'location', 'date', 'new_cases', 'total_cases', 'new_cases_smoothed', 'new_cases_per_million', 'new_cases_smoothed_per_million', 'new_deaths', 'total_deaths', 'new_deaths_smoothed', 'new_deaths_per_million', 'new_deaths_smoothed_per_million', 'total_deaths_per_million', 'mortality_rate', 'population', 'population_density', 'stringency_index']\n",
      "\n",
      " taux de completude des colonnes cles \n",
      "covid - population: 100.0%\n",
      "mpox - population: 100.0%\n",
      "covid - population_density: 89.0%\n",
      "mpox - population_density: 98.1%\n",
      "covid - stringency_index: 48.9%\n",
      "mpox - stringency_index: 15.5%\n",
      "covid - mortality_rate: 90.3%\n",
      "mpox - mortality_rate: 99.3%\n"
     ]
    }
   ],
   "source": [
    "# enrichissement des colonnes manquantes dans mpox\n",
    "print(\" enrichissement des colonnes manquantes dans mpox \")\n",
    "\n",
    "# enrichir continent depuis covid\n",
    "print(\"ajout de la colonne continent...\")\n",
    "continent_mapping = {}\n",
    "for location in covid_countries['location'].unique():\n",
    "    continent = covid_countries[covid_countries['location'] == location]['continent'].iloc[0]\n",
    "    if pd.notna(continent):\n",
    "        continent_mapping[location] = continent\n",
    "\n",
    "mpox_enriched_final['continent'] = mpox_enriched_final['location'].map(continent_mapping)\n",
    "print(f\"continent ajoute pour {mpox_enriched_final['continent'].notna().sum()} lignes\")\n",
    "\n",
    "# stringency_index - donnee temporelle, necessite une jointure par location et date\n",
    "print(\"\\najout de stringency_index...\")\n",
    "# creer un subset de covid avec juste location, date et stringency_index\n",
    "covid_stringency = covid_countries[['location', 'date', 'stringency_index']].dropna(subset=['stringency_index'])\n",
    "\n",
    "# fusionner avec mpox\n",
    "mpox_with_stringency = mpox_enriched_final.merge(\n",
    "    covid_stringency, \n",
    "    on=['location', 'date'], \n",
    "    how='left',\n",
    "    suffixes=('', '_covid')\n",
    ")\n",
    "\n",
    "if 'stringency_index' not in mpox_enriched_final.columns:\n",
    "    mpox_enriched_final['stringency_index'] = mpox_with_stringency['stringency_index']\n",
    "print(f\"stringency_index ajoute pour {mpox_enriched_final['stringency_index'].notna().sum()} lignes\")\n",
    "\n",
    "# reproduction_rate ne peut pas etre transfere car c'est specifique a la maladie\n",
    "print(\"\\nreproduction_rate: specifique a chaque maladie, ne peut pas etre transfere\")\n",
    "\n",
    "# reorganiser les colonnes dans le bon ordre\n",
    "colonnes_disponibles_mpox = [col for col in colonnes_finales if col in mpox_enriched_final.columns or col == 'continent' or col == 'stringency_index']\n",
    "colonnes_disponibles_mpox = [col for col in colonnes_disponibles_mpox if col != 'reproduction_rate']\n",
    "mpox_enriched_final = mpox_enriched_final[colonnes_disponibles_mpox]\n",
    "\n",
    "# validation finale\n",
    "print(\"\\n validation finale \")\n",
    "print(f\"covid_countries_final: {covid_countries_final.shape}\")\n",
    "print(f\"colonnes: {list(covid_countries_final.columns)}\")\n",
    "print(f\"\\nmpox_enriched_final: {mpox_enriched_final.shape}\")\n",
    "print(f\"colonnes: {list(mpox_enriched_final.columns)}\")\n",
    "\n",
    "# statistiques de completude\n",
    "print(\"\\n taux de completude des colonnes cles \")\n",
    "for col in ['population', 'population_density', 'stringency_index', 'mortality_rate']:\n",
    "    if col in covid_countries_final.columns:\n",
    "        taux_covid = covid_countries_final[col].notna().sum() / len(covid_countries_final) * 100\n",
    "        print(f\"covid - {col}: {taux_covid:.1f}%\")\n",
    "    if col in mpox_enriched_final.columns:\n",
    "        taux_mpox = mpox_enriched_final[col].notna().sum() / len(mpox_enriched_final) * 100\n",
    "        print(f\"mpox - {col}: {taux_mpox:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4a397ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ajout des coordonnees geographiques ===\n",
      "telechargement des coordonnees geographiques...\n",
      "colonnes geo disponibles: ['Country', 'Alpha-2 code', 'Alpha-3 code', 'Numeric code', 'Latitude (average)', 'Longitude (average)']\n",
      "nombre de pays avec coordonnees: 256\n",
      "nettoyage des donnees geographiques...\n",
      "\n",
      "ajout des coordonnees aux datasets pays...\n",
      "\n",
      "=== verification de l'ajout des coordonnees ===\n",
      "\n",
      "covid_countries:\n",
      "  lignes avec coordonnees: 405295/421264 (96.2%)\n",
      "  pays avec coordonnees: 232/243 (95.5%)\n",
      "\n",
      "mpox_countries:\n",
      "  lignes avec coordonnees: 119200/121380 (98.2%)\n",
      "  pays avec coordonnees: 134/137 (97.8%)\n",
      "\n",
      "agrégations (sans coordonnees):\n",
      "covid_aggregations: 20163 lignes\n",
      "mpox_aggregations: 7794 lignes\n",
      "\n",
      "exemples de coordonnees ajoutees:\n",
      "France: lat=46.0, lon=2.0\n",
      "Germany: lat=51.0, lon=9.0\n",
      "Brazil: lat=-10.0, lon=-55.0\n",
      "\n",
      "pays sans coordonnees: 11\n",
      "exemples: ['Bonaire Sint Eustatius and Saba', 'Curacao', 'England', 'Kosovo', 'Northern Cyprus']\n",
      "\n",
      "nombre total de colonnes finales avec coordonnees: 22\n"
     ]
    }
   ],
   "source": [
    "# ajout des coordonnees geographiques\n",
    "print(\"=== ajout des coordonnees geographiques ===\")\n",
    "\n",
    "# telecharger les donnees de coordonnees\n",
    "print(\"telechargement des coordonnees geographiques...\")\n",
    "geo_data = pd.read_csv('https://gist.githubusercontent.com/tadast/8827699/raw/f5cac3d42d16b78348610fc4ec301e9234f82821/countries_codes_and_coordinates.csv')\n",
    "\n",
    "# nettoyer les noms de colonnes (espaces et guillemets)\n",
    "geo_data.columns = geo_data.columns.str.strip().str.replace('\"', '')\n",
    "\n",
    "# afficher les colonnes disponibles\n",
    "print(f\"colonnes geo disponibles: {list(geo_data.columns)}\")\n",
    "print(f\"nombre de pays avec coordonnees: {len(geo_data)}\")\n",
    "\n",
    "# preparation des donnees geo\n",
    "geo_subset = geo_data[['Alpha-3 code', 'Latitude (average)', 'Longitude (average)']].copy()\n",
    "geo_subset.columns = ['iso_code', 'latitude', 'longitude']\n",
    "\n",
    "# NETTOYER TOUTES LES VALEURS (espaces et guillemets)\n",
    "print(\"nettoyage des donnees geographiques...\")\n",
    "geo_subset['iso_code'] = geo_subset['iso_code'].str.strip().str.replace('\"', '')\n",
    "geo_subset['latitude'] = geo_subset['latitude'].str.strip().str.replace('\"', '')\n",
    "geo_subset['longitude'] = geo_subset['longitude'].str.strip().str.replace('\"', '')\n",
    "\n",
    "# convertir latitude et longitude en nombres\n",
    "geo_subset['latitude'] = pd.to_numeric(geo_subset['latitude'], errors='coerce')\n",
    "geo_subset['longitude'] = pd.to_numeric(geo_subset['longitude'], errors='coerce')\n",
    "\n",
    "# fonction pour ajouter les coordonnees a un dataset\n",
    "def add_coordinates(df, geo_data):\n",
    "    \"\"\"ajoute latitude et longitude au dataset\"\"\"\n",
    "    df_with_coords = df.merge(\n",
    "        geo_data,\n",
    "        on='iso_code',\n",
    "        how='left'\n",
    "    )\n",
    "    return df_with_coords\n",
    "\n",
    "# application aux datasets pays seulement\n",
    "print(\"\\najout des coordonnees aux datasets pays...\")\n",
    "covid_countries_final = add_coordinates(covid_countries_final, geo_subset)\n",
    "mpox_enriched_final = add_coordinates(mpox_enriched_final, geo_subset)\n",
    "\n",
    "# preparer les datasets agregations pour la sauvegarde (sans coordonnees)\n",
    "covid_aggregations_final = covid_aggregations[[col for col in colonnes_finales if col in covid_aggregations.columns]]\n",
    "mpox_aggregations_final = mpox_aggregations[[col for col in colonnes_finales if col in mpox_aggregations.columns and col != 'reproduction_rate']]\n",
    "\n",
    "# verification de l'ajout\n",
    "print(\"\\n=== verification de l'ajout des coordonnees ===\")\n",
    "for name, df in [('covid_countries', covid_countries_final), \n",
    "                 ('mpox_countries', mpox_enriched_final)]:\n",
    "    if 'latitude' in df.columns and 'longitude' in df.columns:\n",
    "        coords_present = df[['latitude', 'longitude']].notna().all(axis=1).sum()\n",
    "        nb_locations = df['location'].nunique()\n",
    "        pays_avec_coords = df.groupby('location')[['latitude', 'longitude']].first().notna().all(axis=1).sum()\n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"  lignes avec coordonnees: {coords_present}/{len(df)} ({coords_present/len(df)*100:.1f}%)\")\n",
    "        print(f\"  pays avec coordonnees: {pays_avec_coords}/{nb_locations} ({pays_avec_coords/nb_locations*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nagrégations (sans coordonnees):\")\n",
    "print(f\"covid_aggregations: {covid_aggregations_final.shape[0]} lignes\")\n",
    "print(f\"mpox_aggregations: {mpox_aggregations_final.shape[0]} lignes\")\n",
    "\n",
    "# exemples de verification\n",
    "print(\"\\nexemples de coordonnees ajoutees:\")\n",
    "for country in ['France', 'Germany', 'Brazil']:\n",
    "    exemple = covid_countries_final[covid_countries_final['location'] == country][['location', 'latitude', 'longitude']].drop_duplicates()\n",
    "    if not exemple.empty:\n",
    "        print(f\"{country}: lat={exemple['latitude'].iloc[0]:.1f}, lon={exemple['longitude'].iloc[0]:.1f}\")\n",
    "\n",
    "# verifier les pays sans coordonnees\n",
    "pays_sans_coords = covid_countries_final[covid_countries_final['latitude'].isna()]['location'].unique()\n",
    "if len(pays_sans_coords) > 0:\n",
    "    print(f\"\\npays sans coordonnees: {len(pays_sans_coords)}\")\n",
    "    print(f\"exemples: {list(pays_sans_coords)[:5]}\")\n",
    "\n",
    "# mise a jour des colonnes finales\n",
    "colonnes_finales_avec_geo = colonnes_finales + ['latitude', 'longitude']\n",
    "print(f\"\\nnombre total de colonnes finales avec coordonnees: {len(colonnes_finales_avec_geo)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "df9c83c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " sauvegarde des datasets nettoyes \n",
      "fichiers sauvegardes:\n",
      "  - covid_countries_clean.csv\n",
      "  - covid_aggregations_clean.csv\n",
      "  - mpox_countries_clean.csv\n",
      "  - mpox_aggregations_clean.csv\n",
      "\n",
      "resume final de l'etl\n",
      "\n",
      "covid original: 429435 lignes -> covid pays: 421264 + agregations: 20163\n",
      "mpox original: 123852 lignes -> mpox pays: 121380 + agregations: 7794\n",
      "\n",
      "operations effectuees:\n",
      "  1. conversion dates en datetime\n",
      "  2. fusion des doublons (7770 paires dans covid)\n",
      "  3. correction valeurs cumulatives decroissantes (cummax)\n",
      "  4. suppression lignes toutes nan (1 dans mpox)\n",
      "  5. correction reproduction_rate negatif (178 valeurs)\n",
      "  6. calcul mortality_rate avec plafond a 100%\n",
      "  7. separation pays vs agregations\n",
      "  8. enrichissement mpox avec donnees covid\n",
      "  9. selection colonnes finales (22 pour covid, 21 pour mpox)\n",
      " 10. ajout coordonnees geographiques\n",
      "\n",
      " qualite des donnees finales \n",
      "\n",
      "covid_countries:\n",
      "  dimensions: (421264, 22)\n",
      "  plage dates: 2020-01-01 00:00:00 a 2024-08-14 00:00:00\n",
      "  pays uniques: 243\n",
      "  taux global de completude: 92.5%\n",
      "  coordonnees: 405295/421264 lignes (96.2%)\n",
      "  pays avec coordonnees: 232/243 (95.5%)\n",
      "\n",
      "mpox_countries:\n",
      "  dimensions: (121380, 21)\n",
      "  plage dates: 2022-05-01 00:00:00 a 2025-05-31 00:00:00\n",
      "  pays uniques: 137\n",
      "  taux global de completude: 95.7%\n",
      "  coordonnees: 119200/121380 lignes (98.2%)\n",
      "  pays avec coordonnees: 134/137 (97.8%)\n",
      "\n",
      " completude des colonnes cles \n",
      "\n",
      "covid_countries:\n",
      "  population: 100.0%\n",
      "  population_density: 89.2%\n",
      "  stringency_index: 49.2%\n",
      "  mortality_rate: 90.3%\n",
      "  latitude: 96.2%\n",
      "  longitude: 96.2%\n",
      "\n",
      "mpox_countries:\n",
      "  population: 100.0%\n",
      "  population_density: 98.2%\n",
      "  stringency_index: 15.3%\n",
      "  mortality_rate: 99.4%\n",
      "  latitude: 98.2%\n",
      "  longitude: 98.2%\n",
      "\n",
      " verification taille des fichiers \n",
      "\n",
      "etl termine avec succes!\n"
     ]
    }
   ],
   "source": [
    "# sauvegarde et validation finale\n",
    "print(\" sauvegarde des datasets nettoyes \")\n",
    "\n",
    "# sauvegarder les datasets\n",
    "covid_countries_final.to_csv(OUTPUT_DIR / 'covid_countries_clean.csv', index=False)\n",
    "covid_aggregations_final.to_csv(OUTPUT_DIR / 'covid_aggregations_clean.csv', index=False)\n",
    "mpox_enriched_final.to_csv(OUTPUT_DIR / 'mpox_countries_clean.csv', index=False)\n",
    "mpox_aggregations_final.to_csv(OUTPUT_DIR / 'mpox_aggregations_clean.csv', index=False)\n",
    "\n",
    "print(\"fichiers sauvegardes:\")\n",
    "print(\"  - covid_countries_clean.csv\")\n",
    "print(\"  - covid_aggregations_clean.csv\")\n",
    "print(\"  - mpox_countries_clean.csv\")\n",
    "print(\"  - mpox_aggregations_clean.csv\")\n",
    "\n",
    "# resume final de l'etl\n",
    "print(\"\\nresume final de l'etl\")\n",
    "print(f\"\\ncovid original: {covid_raw.shape[0]} lignes -> covid pays: {covid_countries_final.shape[0]} + agregations: {covid_aggregations_final.shape[0]}\")\n",
    "print(f\"mpox original: {mpox_raw.shape[0]} lignes -> mpox pays: {mpox_enriched_final.shape[0]} + agregations: {mpox_aggregations_final.shape[0]}\")\n",
    "\n",
    "print(\"\\noperations effectuees:\")\n",
    "print(\"  1. conversion dates en datetime\")\n",
    "print(\"  2. fusion des doublons (7770 paires dans covid)\")\n",
    "print(\"  3. correction valeurs cumulatives decroissantes (cummax)\")\n",
    "print(\"  4. suppression lignes toutes nan (1 dans mpox)\")\n",
    "print(\"  5. correction reproduction_rate negatif (178 valeurs)\")\n",
    "print(\"  6. calcul mortality_rate avec plafond a 100%\")\n",
    "print(\"  7. separation pays vs agregations\")\n",
    "print(\"  8. enrichissement mpox avec donnees covid\")\n",
    "print(\"  9. selection colonnes finales (22 pour covid, 21 pour mpox)\")\n",
    "print(\" 10. ajout coordonnees geographiques\")\n",
    "\n",
    "# qualite des donnees finales detaillee\n",
    "print(\"\\n qualite des donnees finales \")\n",
    "for name, df in [('covid_countries', covid_countries_final), ('mpox_countries', mpox_enriched_final)]:\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  dimensions: {df.shape}\")\n",
    "    print(f\"  plage dates: {df['date'].min()} a {df['date'].max()}\")\n",
    "    print(f\"  pays uniques: {df['location'].nunique()}\")\n",
    "    print(f\"  taux global de completude: {100 - (df.isnull().sum().sum() / (df.shape[0] * df.shape[1]) * 100):.1f}%\")\n",
    "    \n",
    "    # verification des coordonnees\n",
    "    if 'latitude' in df.columns and 'longitude' in df.columns:\n",
    "        coords_complete = df[['latitude', 'longitude']].notna().all(axis=1).sum()\n",
    "        pays_avec_coords = df.groupby('location')[['latitude', 'longitude']].first().notna().all(axis=1).sum()\n",
    "        print(f\"  coordonnees: {coords_complete}/{len(df)} lignes ({coords_complete/len(df)*100:.1f}%)\")\n",
    "        print(f\"  pays avec coordonnees: {pays_avec_coords}/{df['location'].nunique()} ({pays_avec_coords/df['location'].nunique()*100:.1f}%)\")\n",
    "\n",
    "# taux de completude par colonne importante\n",
    "print(\"\\n completude des colonnes cles \")\n",
    "colonnes_cles = ['population', 'population_density', 'stringency_index', 'mortality_rate', 'latitude', 'longitude']\n",
    "\n",
    "for dataset_name, df in [('covid_countries', covid_countries_final), ('mpox_countries', mpox_enriched_final)]:\n",
    "    print(f\"\\n{dataset_name}:\")\n",
    "    for col in colonnes_cles:\n",
    "        if col in df.columns:\n",
    "            taux = df[col].notna().sum() / len(df) * 100\n",
    "            print(f\"  {col}: {taux:.1f}%\")\n",
    "        else:\n",
    "            print(f\"  {col}: colonne absente\")\n",
    "\n",
    "# verification finale des fichiers\n",
    "print(\"\\n verification taille des fichiers \")\n",
    "for filename in ['covid_countries_clean.csv', 'covid_aggregations_clean.csv', \n",
    "                 'mpox_countries_clean.csv', 'mpox_aggregations_clean.csv']:\n",
    "    if os.path.exists(filename):\n",
    "        size_mb = os.path.getsize(filename) / (1024 * 1024)\n",
    "        print(f\"{filename}: {size_mb:.1f} MB\")\n",
    "\n",
    "print(\"\\netl termine avec succes!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
